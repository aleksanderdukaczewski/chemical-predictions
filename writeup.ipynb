{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "---\n",
    "title: \"THE PROJECT TITLE\"\n",
    "date: 2021-09-04\n",
    "updated: 2021-09-04\n",
    "authors_plus:\n",
    "- \"Aleksander Dukaczewski\"\n",
    "- \"Annie Stevenson\"\n",
    "contacts_plus:\n",
    "- \"https://www.linkedin.com/in/aleksander-dukaczewski-2713911b8/\"\n",
    "- \"https://www.linkedin.com/in/anniestevenson1/\"\n",
    "editor: \"Editor name\"\n",
    "editor_contact: \"https://www.linkedin.com/in/editor\"\n",
    "tags:\n",
    "- machine learning\n",
    "- molecular machine learning\n",
    "- chemistry\n",
    "- solubility\n",
    "- esol\n",
    "- python\n",
    "categories:\n",
    "- []\n",
    "languages:\n",
    "- python3\n",
    "description: \"Short and catchy description of the project\"\n",
    "cover: /banners/polish-countdown.jpg\n",
    "---\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\n",
    "Aqueous solubility is a key physical property of interest in the medicinal and agrochemical industry. Low aqueous solubility of compounds can be a major problem in drug development, as more than 40% of newly developed chemicals are practically insoluble in water. For a drug to be absorbed it needs to be contained in a solution at the site of the absorption and solubility is the main parameter that influences the bioavailability of a molecule. \n",
    "\n",
    "As designing and approving a new drug is an expensive, nearly decade-long process, new methods for the prediction of a compound's aqueous solubility prior to its synthesis could greatly facilitate the process of drug development. Aqueous solubility is also a major factor in the development of insecticides, fungicides and herbicides, so the agrochemical industry can also greatly benefit from new methods of estimating aqueous solubility of compounds without the presence of a physical sample. \n",
    "\n",
    "Machine learning allows us to create models that can predict a compound's aqueous solubility straight from its molecular structure without the presence of a physical sample and without running sophisticated physical simulations.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Methods\n",
    "\n",
    "The entire project was completed sing Python. We used the dataset ESOL, containing the solubilities of 1144 chemical compounds and their structures in the SMILES format."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
    "\n",
    "#installing libraries \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#Reading dataset\n",
    "comp = pd.read_csv(\"raw_esol.csv\")\n",
    "comp\n",
    "comp.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The library rdkit was used to extract features for the model, such as LogP (known as partition coefficient), molecular weight, rotatable bonds, H-bond donor count, H-bond acceptor count, polar surface area, aromatic proportion and non-carbon proportion."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!conda install -c rdkit rdkit -y\n",
    "from rdkit import Chem\n",
    "mol=[Chem.MolFromSmiles(drug) for drug in comp.SMILES]\n",
    "len(mol)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Using rdkit to extract molecule data to set parameters - cLogP, Molecular weight, Rotatable bonds, H-bond donor count, H-bond acceptor count, Polar surface area\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import Lipinski\n",
    "def parameters(smiles, verbose=False):\n",
    "    base_data = []\n",
    "    for s in smiles:\n",
    "        mol=Chem.MolFromSmiles(s)\n",
    "        base_data.append(mol)\n",
    "\n",
    "    data = np.arange(1,1)\n",
    "    r = 0\n",
    "    for m in base_data:\n",
    "        Mol_LogP = Descriptors.MolLogP(m)\n",
    "        Mol_Weight = Descriptors.MolWt(m)\n",
    "        Rotable_Bonds = Descriptors.NumRotatableBonds(m)\n",
    "        H_bond_donor = Lipinski.NumHDonors(m)\n",
    "        H_bond_acceptor = Lipinski.NumHAcceptors(m)\n",
    "        Polar_Surface_Area = Descriptors.TPSA(m)\n",
    "\n",
    "        row_data = np.array([Mol_LogP,\n",
    "                             Mol_Weight,\n",
    "                             Rotable_Bonds,\n",
    "                             H_bond_donor,\n",
    "                             H_bond_acceptor,\n",
    "                             Polar_Surface_Area])\n",
    "        if (r==0):\n",
    "            data = row_data\n",
    "        else:\n",
    "            data = np.vstack([data, row_data])\n",
    "        r = r + 1\n",
    "\n",
    "    column_names = [\"cLogP\", \"Molecular weight\", \"Rotatable bonds\", \"H-bond donor count\", \"H-bond acceptor count\", \"Polar surface area\"]\n",
    "    df = pd.DataFrame(data=data, columns=column_names)\n",
    "    return df"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rdkit'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-37fcd5b1a4d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Using rdkit to extract molecule data to set parameters - cLogP, Molecular weight, Rotatable bonds, H-bond donor count, H-bond acceptor count, Polar surface area\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDescriptors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLipinski\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbase_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rdkit'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculating aromatic propertion\n",
    "def Aro_Atoms(mol):\n",
    "    aro_atoms = [mol.GetAtomWithIdx(i).GetIsAromatic() for i in range(mol.GetNumAtoms())]\n",
    "    \n",
    "    a_atoms = []\n",
    "    for a in aro_atoms:\n",
    "        if a == True:\n",
    "            a_atoms.append(a)\n",
    "    sum_a_atoms = sum(a_atoms)\n",
    "    return sum_a_atoms\n",
    "\n",
    "aromatic_proportion = [Aro_Atoms(element)/Descriptors.HeavyAtomCount(element) for element in mol]\n",
    "aromatic_proportion = pd.DataFrame(aromatic_proportion, columns=['Aromatic proportion'])\n",
    "aromatic_proportion\n",
    "\n",
    "# Calculating non-carbon propertions\n",
    "non_carbon_proportion = [Lipinski.NumHeteroatoms(element)/Lipinski.HeavyAtomCount(element) for element in mol]\n",
    "non_carbon_proportion = pd.DataFrame(non_carbon_proportion, columns=['Non carbon proportion'])\n",
    "non_carbon_proportion\n",
    "\n",
    "# X and Y matrix \n",
    "X = pd.concat([descriptors, aromatic_proportion, non_carbon_proportion], axis=1)\n",
    "Y = comp.iloc[:,1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Regression\n",
    "\n",
    "We decided to reproduce the original ESOL research paper and trained a linear regression model from the library sklearn to predict *log(solubility)* to see if we can create a machine learning model with decent predictive power basing on the features we had previously extracted."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Splitting data into training and test data sets (80%-20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear = LinearRegression()\n",
    "linear.fit(X_train, Y_train)\n",
    "linear_Y_train_pred = linear.predict(X_train)\n",
    "\n",
    "#Calculating RMSE (Root mean squared error - which tells you how far the regression line data points are away from actual values)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rmse_linear_Y_train_pred = sqrt(mean_squared_error(Y_train, linear_Y_train_pred))\n",
    "\n",
    "#Calculating R^2 Score \n",
    "from sklearn.metrics import r2_score\n",
    "linear_Y_train_score = r2_score(Y_train, linear_Y_train_pred)\n",
    "\n",
    "#Applying linear regression model to testing data set \n",
    "linear_Y_test_pred = linear.predict(X_test)\n",
    "\n",
    "#Calculating RMSE\n",
    "rmse_linear_Y_test_pred = sqrt(mean_squared_error(Y_test, linear_Y_test_pred))\n",
    "\n",
    "#Calculating R^2 Score \n",
    "linear_Y_test_score = r2_score(Y_test, linear_Y_test_pred)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This resulted in a linear regression model with the intercept value of approximately $0.118$, training $RMSE$ and $R^2$ values of approximately $0.964$ and $0.788$, and testing $RMSE$ and $R^2$ values of approximately $0.993$ and $0.779$. The model had some predictive power, which inspired us to create a more sophisticated neural network model for the same purpose.\n",
    "</br>\n",
    "![linear_results](plot_horizontal_logS.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network\n",
    "\n",
    "We created a neural network model using keras and tensorflow."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "ann = Sequential()\n",
    "ann.add(Dense(60, input_dim=8, activation='tanh'))\n",
    "ann.add(Dense(40, input_dim=60, activation='tanh'))\n",
    "ann.add(Dense(20, input_dim=40, activation='tanh'))\n",
    "ann.add(Dense(7, input_dim=20, activation='tanh'))\n",
    "ann.add(Dense(1, input_dim=7, activation='linear'))\n",
    "\n",
    "tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.99)\n",
    "ann.compile(loss='mean_squared_error', optimizer='adam', metrics='mse')\n",
    "ann.summary\n",
    "\n",
    "#Fitting/ tuning the model \n",
    "ann.fit(X_train, Y_train, epochs=100, batch_size=32, validation_split=0.10, verbose=True)\n",
    "\n",
    "#Applying the model to the training data set \n",
    "ann_Y_train_pred = ann.predict(X_train)\n",
    "\n",
    "#Calculating RMSE\n",
    "rmse_ann_Y_train_pred = sqrt(mean_squared_error(Y_train, ann_Y_train_pred))\n",
    "\n",
    "#Calculating R^2 Score \n",
    "ann_Y_train_score = r2_score(Y_train, ann_Y_train_pred)\n",
    "\n",
    "#Test data set \n",
    "ann_Y_test_pred = ann.predict(X_test)\n",
    "\n",
    "#Calculating RMSE\n",
    "rmse_ann_Y_test_pred = sqrt(mean_squared_error(Y_test, ann_Y_test_pred))\n",
    "\n",
    "#Calculating R^2 Score\n",
    "ann_Y_test_score = r2_score(Y_test, ann_Y_test_pred)\n",
    "\n",
    "#Molecule number array for ANN\n",
    "mol_numbers = np.arange(1, 230, 1).reshape(229,1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This resulted in a neural network with training $RMSE$ and $R^2$ values of approximately $0.721$ and $0.881$, and testing $RMSE$ and $R^2$ values of approximately $0.722$ and $0.881$.\n",
    "</br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusions\n",
    "\n",
    "The neural network model resulted in lower values of root-mean-square error ($RMSE$) and values of the coefficient of determination ($R^2$) closer to 1, suggesting better predictive power. The models can be compared using this graph, showing the distribution of measured molecule solubility and predicted molecule solubility of both models.\n",
    "</br>\n",
    "![comparison](models_comparison.png)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
